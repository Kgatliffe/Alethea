---
title: "R Notebook"
output: html_notebook
---

```{r}
#' Computes the reinforcement learning policy
#'
#' Computes reinforcement learning policy from a given state-action table Q.
#' The policy is the decision-making function of the agent and defines the learning
#' agent's behavior at a given time.
#'
#' @param x Variable which encodes the behavior of the agent. This can be
#' either a \code{matrix}, \code{data.frame} or an \code{\link{rl}} object.
#' @seealso \code{\link{ReinforcementLearning}}
#' @return Returns the learned policy.
#' @examples
#' # Create exemplary state-action table (Q) with 2 actions and 3 states
#' Q <- data.frame("up" = c(-1, 0, 1), "down" = c(-1, 1, 0))
#'
#' # Show best possible action in each state
#' computePolicy(Q)
#'
#' @rdname computePolicy
#' @export
computePolicy <- function(x) {
  UseMethod("computePolicy", x)
}

#' @export
computePolicy.matrix <- function(x) {
  policy <- colnames(x)[apply(x, 1, which.max)]
  names(policy) <- rownames(x)
  return(policy)
}

#' @export
computePolicy.data.frame <- function(x) {
  return(computePolicy(as.matrix(x)))
}

#' @export
computePolicy.rl <- function(x) {
  return(computePolicy(x$Q))
}

#' @export
computePolicy.default <- function(x) {
  stop("Argument invalid.")
}

#' Computes the reinforcement learning policy
#'
#' Deprecated. Please use [ReinforcementLearning::computePolicy()] instead.
#'
#' @param x Variable which encodes the behavior of the agent. This can be
#' either a \code{matrix}, \code{data.frame} or an \code{\link{rl}} object.
#' @seealso \code{\link{ReinforcementLearning}}
#' @return Returns the learned policy.
#' @rdname policy
#' @export
policy <- function(x) {
  .Deprecated("computePolicy")
  computePolicy(x)
}

```

```{r}
print.rl <- function(x, ...) {
  cat("State-Action function Q\n")
  print(x$Q)
  cat("\nPolicy\n")
  print(x$Policy)
  cat("\nReward (last iteration)\n")
  print(x$Reward)
}
```
 
```{r}
createsamplefunction <- function(simplepop, ...) {
id_num<-sample(100:140, 40, replace=F)
for(i in 1: nrow(simplepop))
{
  simplepop$ID[i]<-id_num[i]
  simplepop$Code[i]<-paste0(simplepop$ID[i],'.',simplepop$Type[i],'.',simplepop$Susp[i])
}
id_num0<-sample(1:40, 40, replace=F)
Left<-NA
Right<-NA
LeftCode<-NA
RightCode<-NA
LeftReward<-NA
RightReward<-NA
State<-NA
NextState<-NA
for(i in 1: nrow(simplepop)/2)
{
  id_num1<-id_num0[i]
  id_num2<-id_num0[i+20]
  Left[i]<-id_num1
  Right[i]<-id_num2
  LeftCode[i]<-simplepop$Code[id_num1]
  RightCode[i]<-simplepop$Code[id_num2]
  LeftReward[i]<-simplepop$Crim[id_num1]
  RightReward[i]<-simplepop$Crim[id_num2]
  State[i]<-paste0(LeftCode[i],'.',RightCode[i])
  NextState[i-1]<-paste0(LeftCode[i],'.',RightCode[i])
  NextState[i]<-"End"  
}
createsample<-data.frame(Left, Right,LeftCode, RightCode, LeftReward, RightReward, State, NextState)
return(createsample)
}
statediagramfunction <- function(createsample, ...) {
time = 20
detain = 3
move = 1
statemap<-data.frame("State"=paste0(time,".",createsample$State[1]), "Action"="Left", "Reward"=createsample$LeftReward[1], "NextState"=paste0(time-detain,".",createsample$NextState[1]))
nextrow<-data.frame("State"=paste0(time,".",createsample$State[1]), "Action"="Right", "Reward"=createsample$RightReward[1], "NextState"=paste0(time-detain,".",createsample$NextState[1]))
statemap<-rbind(statemap,nextrow)
nextrow<-data.frame("State"=paste0(time,".",createsample$State[1]), "Action"="None", "Reward"=0, "NextState"=paste0(time-move,".",createsample$NextState[1]))
statemap<-rbind(statemap,nextrow)

for(i in 2:1000)
{
  statedummy<-as.character(statemap$NextState[i])
    flag<-0
    if (is.na(statedummy))
{}
      else if (statedummy=="End")
{}
  else
  {
  for(j in 1:nrow(statemap))
  {
    if (statedummy==statemap$State[j])  
    {
      flag<-1
    }
  }
  if(flag==0)
  {
    openstate<-unlist(stri_split_fixed(as.character(statedummy),".", fixed = TRUE, n=2))
        for (k in 1:nrow(createsample))
    {
      if (openstate[2]==as.character(createsample$State[k]))
      {
        timedet<-as.numeric(openstate[1])-detain
        timemove<-as.numeric(openstate[1])-move
if(as.numeric(openstate[1])>=detain)
{
                nextrow<-data.frame("State"=statedummy, "Action"="Left", "Reward"=createsample$LeftReward[k], "NextState"=paste0(timedet,".",createsample$State[k+1]))
        nextrow2<-data.frame("State"=statedummy, "Action"="Right", "Reward"=createsample$RightReward[k], 
 "NextState"=paste0(timedet,".",createsample$State[k+1]))
} 
        else if(as.numeric(openstate[1])<detain)
{
                nextrow<-data.frame("State"=statedummy, "Action"="Left", "Reward"=createsample$LeftReward[k], "NextState"="End")
        nextrow2<-data.frame("State"=statedummy, "Action"="Right", "Reward"=createsample$RightReward[k], 
 "NextState"="End")
} 
        if(as.numeric(openstate[1])>=move)
{
        nextrow3<-data.frame("State"=statedummy, "Action"="None", "Reward"=0, "NextState"=paste0(timemove,".",createsample$State[k+1]))
        statemap<-rbind(statemap, nextrow, nextrow2, nextrow3)
        }
        else if (as.numeric(openstate[1])<move)
{
        nextrow3<-data.frame("State"=statedummy, "Action"="None", "Reward"=0, "NextState"="End")
        statemap<-rbind(statemap, nextrow, nextrow2, nextrow3)
      }
    } 
  }
  }
}
}
return(statemap)
}
```

```{r}
runRLtrain<-function(simpledat, trainmodelold)
{
# Load dataset
simpledat$State<-as.character(simpledat$State)
simpledat$NextState<-as.character(simpledat$NextState)
simpledat$Action<-as.character(simpledat$Action)
# Define reinforcement learning parameters
control <- list(alpha = 0.2, gamma = 0.4, epsilon = 0.1)

# Perform reinforcement learning
trainmodelnew <- ReinforcementLearning(simpledat, s = "State", a = "Action", r = 
                                 "Reward", 
                               s_new = "NextState", iter = 1000, control = control, model=trainmodelold)
# Print optimal policy
return(trainmodelnew)
}

```
```{r}
runRLtraininit<-function(simpledat)
{
# Load dataset
simpledat$State<-as.character(simpledat$State)
simpledat$NextState<-as.character(simpledat$NextState)
simpledat$Action<-as.character(simpledat$Action)
# Define reinforcement learning parameters
control <- list(alpha = 0.2, gamma = 0.4, epsilon = 0.1)

# Perform reinforcement learning
trainmodelnew <- ReinforcementLearning(simpledat, s = "State", a = "Action", r = 
                                 "Reward", 
                               s_new = "NextState", iter = 1000, control = control)
# Print optimal policy
return(trainmodelnew)
}

```
```{r}
library(stringi)
library(dplyr)
library(ReinforcementLearning)

setwd("~/Alethea")
simplepop <- read.csv("~/Alethea/simplepop.csv")
createsample<-createsamplefunction(simplepop)
train<-statediagramfunction(createsample)
trainmodel<-runRLtraininit(train)

for (m in 100:199)
{
createsample<-createsamplefunction(simplepop)
train<-statediagramfunction(createsample)
trainmodel<-runRLtrain(train, trainmodel)
policytrain<-computePolicy(trainmodel)
}
View(policytrain)

createsample<-createsamplefunction(simplepop)
test<-statediagramfunction(createsample)
testmodel<-runRLtrain(test,trainmodel)
```
